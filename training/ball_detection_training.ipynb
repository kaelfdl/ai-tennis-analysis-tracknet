{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget 'https://drive.usercontent.google.com/download?id=1DQ3ZbvokTsgOq6x-ay6O8U2W4a8e3LFw&export=download&confirm=yes' -O 'dataset/tennis_ball_det_dataset.zip'\n",
    "#!unzip 'dataset/tennis_ball_det_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 30\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/tennis_ball/images/game1/Clip1/Label.csv'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    df = pd.read_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size, variance):\n",
    "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
    "    g = np.exp(-(x**2 + y**2)/float(2*variance))\n",
    "    return g\n",
    "\n",
    "variance = 10\n",
    "g = gaussian_kernel(1, variance)\n",
    "print(len(g))\n",
    "plt.imshow(g, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian(size, variance):\n",
    "    gaussian_kernel_array = gaussian_kernel(size, variance)\n",
    "    gaussian_kernel_array = gaussian_kernel_array * 255 / gaussian_kernel_array[int(len(gaussian_kernel_array) / 2)][int(len(gaussian_kernel_array) / 2)]\n",
    "    gaussian_kernel_array = gaussian_kernel_array.astype(int)\n",
    "    return gaussian_kernel_array\n",
    "\n",
    "img = create_gaussian(3, 10)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth_images(path_input, path_output, size, variance, width, height):\n",
    "    gaussian_kernel_array = create_gaussian(size, variance)\n",
    "    for game_id in range(1,11):\n",
    "        game = f'game{game_id}'\n",
    "        clips = os.listdir(os.path.join(path_input, game))\n",
    "        for clip in clips:\n",
    "            print(f'game = {game}, clip = {clip}')\n",
    "\n",
    "            path_out_game = os.path.join(path_output, game)\n",
    "            if not os.path.exists(path_out_game):\n",
    "                os.makedirs(path_out_game)\n",
    "            \n",
    "            path_out_clip = os.path.join(path_out_game, clip)\n",
    "            if not os.path.exists(path_out_clip):\n",
    "                os.makedirs(path_out_clip)\n",
    "\n",
    "            path_labels = os.path.join(os.path.join(path_input, game, clip), 'Label.csv')\n",
    "            labels = pd.read_csv(path_labels)\n",
    "            for idx in range(labels.shape[0]):\n",
    "                file_name, vis, x, y, _ = labels.loc[idx, :]\n",
    "                heatmap = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "                if vis != 0:\n",
    "                    x = int(x)\n",
    "                    y = int(y)\n",
    "                    for i in range(-size, size+1):\n",
    "                        for j in range(-size, size+1):\n",
    "                            if x+i < width and x+i >= 0 and y+j < height and y+j >= 0:\n",
    "                                temp = gaussian_kernel_array[i+size][j+size]\n",
    "                                if temp > 0:\n",
    "                                    heatmap[y+j, x+i] = (temp, temp, temp)\n",
    "                    \n",
    "                cv2.imwrite(os.path.join(path_out_clip, file_name), heatmap)\n",
    "\n",
    "#create_ground_truth_images('dataset/tennis_ball/images', 'dataset/tennis_ball/gts', 20, 10, 1280, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth_labels(path_input, path_output, train_rate=0.7):\n",
    "    df = pd.DataFrame()\n",
    "    for game_id in range(1, 11):\n",
    "        game = f'game{game_id}'\n",
    "        clips = os.listdir(os.path.join(path_input, game))\n",
    "        for clip in clips:\n",
    "            labels = pd.read_csv(os.path.join(path_input, game, clip, 'Label.csv'))\n",
    "            labels['ground_truth_path'] = 'gts/' + game + '/' + clip + '/' + labels['file name']\n",
    "            labels['path1'] = 'images/' + game + '/' + clip + '/' + labels['file name']\n",
    "            labels_target = labels[2:]\n",
    "            labels_target.loc[:, 'path2'] = list(labels['path1'][1:-1])\n",
    "            labels_target.loc[:, 'path3'] = list(labels['path1'][:-2])\n",
    "            df = pd.concat([df, labels_target])\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[['path1', 'path2', 'path3', 'ground_truth_path', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n",
    "    df = df.sample(frac=1)\n",
    "    num_train = int(df.shape[0] * train_rate)\n",
    "    df_train = df[:num_train]\n",
    "    df_val = df[num_train:]\n",
    "    df_train.to_csv(os.path.join(path_output, 'labels_train.csv'), index=False)\n",
    "    df_val.to_csv(os.path.join(path_output, 'labels_val.csv'), index=False)\n",
    "\n",
    "#create_ground_truth_labels('dataset/tennis_ball/images', 'dataset/tennis_ball')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_three_frames(frame1, frame2, frame3, width, height):\n",
    "    # Resize and type converting for each frame\n",
    "    img = cv2.resize(frame1, (width, height))\n",
    "    # Input must be float type\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    # Resize\n",
    "    img1 = cv2.resize(frame2, (width, height))\n",
    "    # Input must be float type\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    # Resize\n",
    "    img2 = cv2.resize(frame3, (width, height))\n",
    "    # Input must be float type\n",
    "    img2 = img2.astype(np.float32)\n",
    "\n",
    "    # combine three images to (width, height, rgb * 3)\n",
    "    imgs = np.concatenate((img, img1, img2), axis=2)\n",
    "\n",
    "    # since the ordering of TrackNet is channels first, we need to change the axis\n",
    "    imgs = np.rollaxis(imgs, 2, 0)\n",
    "\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallDataset(Dataset):\n",
    "    def __init__(self, mode, input_height=360, input_width=640):\n",
    "        self.path_dataset = 'dataset/tennis_ball'\n",
    "        assert mode in ['train', 'val'], 'incorrect mode'\n",
    "        self.data = pd.read_csv(os.path.join(self.path_dataset, f'labels_{mode}.csv'))\n",
    "        print(f'mode = {mode}, samples = {self.data.shape[0]}') \n",
    "\n",
    "        self.width = input_width\n",
    "        self.height = input_height\n",
    "\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, path_prev, path_preprev, path_gt, x, y, status, vis = self.data.loc[idx, :]\n",
    "\n",
    "        path = os.path.join(self.path_dataset, path)\n",
    "        path_prev = os.path.join(self.path_dataset, path_prev)\n",
    "        path_preprev = os.path.join(self.path_dataset, path_preprev)\n",
    "        path_gt = os.path.join(self.path_dataset, path_gt)\n",
    "\n",
    "        if math.isnan(x):\n",
    "            x = -1\n",
    "            y = -1\n",
    "        \n",
    "        inputs = self.get_input(path, path_prev, path_preprev)\n",
    "        outputs = self.get_output(path_gt)\n",
    "\n",
    "        return inputs, outputs, x, y, vis\n",
    "\n",
    "    def get_input(self, path, path_prev, path_preprev):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (self.width, self.height))\n",
    "\n",
    "        img_prev = cv2.imread(path_prev)\n",
    "        img_prev = cv2.resize(img_prev, (self.width, self.height))\n",
    "\n",
    "        img_preprev = cv2.imread(path_preprev)\n",
    "        img_preprev = cv2.resize(img_preprev, (self.width, self.height))\n",
    "\n",
    "        imgs = np.concatenate((img, img_prev, img_preprev), axis=2)\n",
    "        imgs = imgs.astype(np.float32) / 255.0\n",
    "\n",
    "        imgs = np.rollaxis(imgs, 2, 0)\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def get_output(self, path_gt):\n",
    "        img = cv2.imread(path_gt)\n",
    "        img = cv2.resize(img, (self.width, self.height))\n",
    "        img = img[:, :, 0]\n",
    "        img = np.reshape(img, (self.width * self.height))\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BallDataset('train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, gt, x, y, vis = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0]\n",
    "y = y[0]\n",
    "\n",
    "a = np.array(imgs[0])\n",
    "b = a[:3]\n",
    "c = a[3:6]\n",
    "d = a[6:]\n",
    "# a = np.rollaxis(a, 0, 3)\n",
    "b = np.rollaxis(b, 0, 3)\n",
    "c = np.rollaxis(c, 0, 3)\n",
    "d = np.rollaxis(d, 0, 3)\n",
    "fig, ax = plt.subplots(4, 1, figsize=(20, 20))\n",
    "\n",
    "e = np.array(gt)\n",
    "e = np.reshape(e[0], (360, 640, 1))\n",
    "\n",
    "ax = plt.subplot(411)\n",
    "ax.imshow(e, cmap='gray')\n",
    "print(x/2, y/2)\n",
    "circle = Circle((x/2, y/2), 5)\n",
    "ax.add_patch(circle)\n",
    "ax = plt.subplot(412)\n",
    "ax.imshow(b)\n",
    "ax = plt.subplot(413)\n",
    "ax.imshow(c)\n",
    "ax = plt.subplot(414)\n",
    "ax.imshow(d)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='notebook_images/tracknet_architecture.png' style='width:720px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True, bn=True):\n",
    "        super().__init__()\n",
    "        if bn:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class BallTrackNet(nn.Module):\n",
    "    def __init__(self, out_channels=256, bn=True):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # Encoder layers\n",
    "        layer_1 = ConvBlock(in_channels=9, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_2 = ConvBlock(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        layer_4 = ConvBlock(in_channels=64, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_5 = ConvBlock(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_6 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        layer_7 = ConvBlock(in_channels=128, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_8 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_9 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_10 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        layer_11 = ConvBlock(in_channels=256, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_12 = ConvBlock(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_13 = ConvBlock(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "\n",
    "        self.encoder = nn.Sequential(layer_1, layer_2, layer_3, layer_4, layer_5, layer_6, layer_7, layer_8, layer_9, layer_10, layer_11, layer_12, layer_13)\n",
    "        \n",
    "        # Decoder layers\n",
    "        layer_14 = nn.Upsample(scale_factor=2)\n",
    "        layer_15 = ConvBlock(in_channels=512, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_16 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_17 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_18 = nn.Upsample(scale_factor=2)\n",
    "        layer_19 = ConvBlock(in_channels=256, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_20 = ConvBlock(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_21 = nn.Upsample(scale_factor=2)\n",
    "        layer_22 = ConvBlock(in_channels=128, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_23 = ConvBlock(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "        layer_24 = ConvBlock(in_channels=64, out_channels=self.out_channels, kernel_size=3, padding=1, bias=True, bn=bn)\n",
    "\n",
    "        self.decoder = nn.Sequential(layer_14, layer_15, layer_16, layer_17, layer_18, layer_19, layer_20, layer_21, layer_22, layer_23, layer_24)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self._init_weights()\n",
    "    \n",
    "\n",
    "    def forward(self, x, testing=False):\n",
    "        batch_size = x.size(0)\n",
    "        features = self.encoder(x)\n",
    "        scores_map = self.decoder(features)\n",
    "        output = scores_map.reshape(batch_size, self.out_channels, -1)\n",
    "\n",
    "        if testing:\n",
    "            output = self.softmax(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.uniform_(module.weight, -0.05, 0.05)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def inference(self, frames: torch.Tensor):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if len(frames.shape) == 3:\n",
    "                frames = frames.unsqueeze(0)\n",
    "            if next(self.parameters()).is_cuda:\n",
    "                frames.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            output = self(frames, True)\n",
    "            output = output.argmax(dim=1).detach().cpu().numpy()\n",
    "            if self.out_channels == 2:\n",
    "                output *= 255\n",
    "            x, y = self.get_center_ball(output)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    \n",
    "    def get_center_ball(self, output):\n",
    "    \n",
    "        output = output.reshape((360, 640))\n",
    "\n",
    "        # cv2 image must be np.uint8\n",
    "        output = output.astype(np.uint8)\n",
    "\n",
    "        # reshape image size\n",
    "        heatmap = cv2.resize(output, (640, 360))\n",
    "\n",
    "        # heatmap is converted into a binary image by threshold method\n",
    "        ret, heatmap = cv2.threshold(heatmap, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # find the circle in image with 2 <= radius <=7\n",
    "        circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=8, minRadius=2, maxRadius=7)\n",
    "        \n",
    "        \n",
    "\n",
    "        # check if there is any tennis ball detected\n",
    "        if circles is not None:\n",
    "            if len(circles) == 1:\n",
    "                x = int(circles[0][0][0])\n",
    "                y = int(circles[0][0][1])\n",
    "            \n",
    "                return x, y\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def train(model, train_loader, optimizer, device, epoch, max_iters=200):\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for iter_id, batch in enumerate(train_loader):\n",
    "        X, y = batch[0].to(device), torch.tensor(batch[1], dtype=torch.long).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "        #print(f'epoch: {epoch}, loss: {loss:>7f}, iter: [{iter_id}/{max_iters}], time: {duration}')\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if iter_id > max_iters - 1:\n",
    "            break\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device, epoch, min_dist=5):\n",
    "    losses = []\n",
    "    tp = [0, 0, 0, 0]\n",
    "    fp = [0, 0, 0, 0]\n",
    "    tn = [0, 0, 0, 0]\n",
    "    fn = [0, 0, 0, 0]\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    for iter_id, batch in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            X, y = batch[0].to(device), torch.tensor(batch[1], dtype=torch.long).to(device)\n",
    "            \n",
    "            out = model(X)\n",
    "            loss = loss_fn(out, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # metrics\n",
    "            output = out.argmax(dim=1).detach().cpu().numpy()\n",
    "            for i in range(len(output)):\n",
    "                x_pred, y_pred = postprocess(output[i])\n",
    "                x_gt = batch[2][i]\n",
    "                y_gt = batch[3][i]\n",
    "                vis = batch[4][i]\n",
    "                \n",
    "                if x_pred:\n",
    "                    if vis != 0:\n",
    "                        dst = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n",
    "\n",
    "                        if dst < min_dist:\n",
    "                            tp[vis] += 1\n",
    "                        else:\n",
    "                            fp[vis] +=1\n",
    "                    else:\n",
    "                        fp[vis] += 1\n",
    "\n",
    "                if not x_pred:\n",
    "                    if vis != 0:\n",
    "                        fn[vis] += 1\n",
    "                    else:\n",
    "                        tn[vis] += 1\n",
    "            \n",
    "            #print(f'val | epoch = {epoch}, iter = [{iter_id}/{len(val_loader)}, loss = {np.mean(losses):7f}, tp = {sum(tp)}, tn = {sum(tn)}, fp = {sum(fp)}, fn = {sum(fn)}')\n",
    "            \n",
    "    eps = 1e-15\n",
    "    precision = sum(tp) / (sum(tp) + sum(fp) + eps)\n",
    "    vc1 = tp[1] + fp[1] + tn[1] + fn[1]\n",
    "    vc2 = tp[2] + fp[2] + tn[2] + fn[2]\n",
    "    vc3 = tp[3] + fp[3] + tn[3] + fn[3]\n",
    "    recall = sum(tp) / (vc1 + vc2 + vc3 + eps)\n",
    "    f1 = 2* precision * recall / (precision + recall + eps)\n",
    "\n",
    "    print(f'precision = {precision}')\n",
    "    print(f'recall = {recall}')\n",
    "    print(f'f1 = {f1}')\n",
    "\n",
    "    return np.mean(losses), precision, recall, f1\n",
    "    \n",
    "\n",
    "def postprocess(feature_map, scale=2):\n",
    "    feature_map *= 255\n",
    "    feature_map = feature_map.reshape((360, 640))\n",
    "    feature_map = feature_map.astype(np.uint8)\n",
    "    ret, heatmap = cv2.threshold(feature_map, 127, 255, cv2.THRESH_BINARY)\n",
    "    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=2, maxRadius=7)\n",
    "    x, y = None, None\n",
    "\n",
    "    if circles is not None:\n",
    "        if len(circles) == 1:\n",
    "            x = circles[0][0][0]*scale\n",
    "            y = circles[0][0][1]*scale\n",
    "    \n",
    "    return x, y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallDetector:\n",
    "    def __init__(self, device, save_state=None, out_channels=2):\n",
    "        self.device = device\n",
    "\n",
    "        # Load TrackNet model weights\n",
    "        self.detector = BallTrackNet(out_channels=out_channels)\n",
    "        saved_state_dict = torch.load(save_state, map_location=torch.device('cpu'))\n",
    "        self.detector.load_state_dict(saved_state_dict['state_dict'])\n",
    "        self.detector.eval().to(self.device)\n",
    "\n",
    "        self.current_frame = None\n",
    "        self.last_frame = None\n",
    "        self.before_last_frame = None\n",
    "\n",
    "        self.video_width = None\n",
    "        self.video_height = None\n",
    "        self.model_input_width = 640\n",
    "        self.model_input_height = 360\n",
    "\n",
    "        self.threshold_dist = 100\n",
    "        self.xy_coordinates = np.array([[None, None], [None, None]])\n",
    "\n",
    "        self.bounces_indices = []\n",
    "\n",
    "    def detect_ball(self, frame):\n",
    "        # save frame dimensions\n",
    "        if self.video_width is None:\n",
    "            self.video_width = frame.shape[1]\n",
    "            self.video_height = frame.shape[0]\n",
    "        \n",
    "        self.last_frame = self.before_last_frame\n",
    "        self.before_last_frame = self.current_frame\n",
    "        self.current_frame = frame.copy()\n",
    "\n",
    "        # detect only if 3 frames were given\n",
    "        if self.last_frame is not None:\n",
    "            # combine the frames into 1 input tensor\n",
    "            frames = combine_three_frames(self.current_frame, self.before_last_frame, self.last_frame, self.model_input_width, self.model_input_height)\n",
    "\n",
    "            frames = (torch.from_numpy(frames) / 255).to(self.device)\n",
    "\n",
    "            x, y = self.detector.inference(frames)\n",
    "            if x is not None:\n",
    "                # rescale the indices to fit dimensions\n",
    "                x = int(x * (self.video_width / self.model_input_width))\n",
    "                y = int(y * (self.video_height / self.model_input_height))\n",
    "\n",
    "                # check the distance from previous location and remove outliers\n",
    "                if self.xy_coordinates[-1][0] is not None:\n",
    "                    if np.linalg.norm(np.array([x, y]) - self.xy_coordinates[-1]) > self.threshold_dist:\n",
    "                        x, y = None, None\n",
    "        \n",
    "            self.xy_coordinates = np.append(self.xy_coordinates, np.array([[x, y]]), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = BallDataset('val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n",
    "    torch.save(state, checkpoint_dir)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_dir, best_model_dir)\n",
    "\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "from torchinfo import summary\n",
    "\n",
    "exp_id = 1\n",
    "exps_path = f'exps/{exp_id}'\n",
    "\n",
    "tb_path = os.path.join(exps_path, 'plots')\n",
    "if not os.path.exists(tb_path):\n",
    "    os.makedirs(tb_path)\n",
    "log_writer = SummaryWriter(tb_path)\n",
    "model_last_path = os.path.join(exps_path, 'model_last.pt')\n",
    "model_best_path = os.path.join(exps_path, 'model_best.pt')\n",
    "\n",
    "\n",
    "\n",
    "def train_tracknet():\n",
    "    model = BallTrackNet()\n",
    "    epochs = 500\n",
    "    steps_per_epoch = 200\n",
    "    lr = 1.0\n",
    "    optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "    val_interval = 50\n",
    "\n",
    "    val_best_metric = 0\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    model, optimizer, start_epoch = load_ckp(model_last_path, model, optimizer)\n",
    "\n",
    "    print(summary(model, input_size=(2, 9, 360, 640)))\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "        print(epoch)\n",
    "        train_start_time = time.time()\n",
    "        train_loss = train(model, train_loader, optimizer, device, epoch, max_iters=steps_per_epoch)\n",
    "        train_end_time = time.time()\n",
    "        train_duration = time.strftime('%H:%M:%S', time.gmtime(train_end_time - train_start_time))\n",
    "        \n",
    "        print(f'Train | Epoch: {epoch} / {epochs} | Loss: {train_loss} | Time: {train_duration}')\n",
    "        log_writer.add_scalar('Train/training_loss', train_loss, epoch)\n",
    "        log_writer.add_scalar('Train/lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        save_ckp(checkpoint, False, model_last_path, model_best_path)\n",
    "\n",
    "        if (epoch > 0) & (epoch % val_interval == 0):\n",
    "            val_start_time = time.time()\n",
    "            val_loss, precision, recall, f1 = validate(model, val_loader, device, epoch)\n",
    "            val_end_time = time.time()\n",
    "            val_duration = time.strftime('%H:%M:%S', time.gmtime(val_end_time - val_start_time))\n",
    "            \n",
    "            print(f'Val | Epoch: {epoch} / {epochs} | Loss: {val_loss} | Time: {val_duration}')\n",
    "            log_writer.add_scalar('Val/loss', val_loss, epoch)\n",
    "            log_writer.add_scalar('Val/precision', precision, epoch)\n",
    "            log_writer.add_scalar('Val/recall', recall, epoch)\n",
    "            log_writer.add_scalar('Val/f1', f1, epoch)\n",
    "            \n",
    "            if f1 > val_best_metric:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "                val_best_metric = f1\n",
    "                save_ckp(checkpoint, True, model_last_path, model_best_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))\n",
    "\n",
    "    print(f'Summary | Epochs: {epochs} | Time: {duration} | Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.video_utils import read_video, save_video\n",
    "\n",
    "input_video_title = 'input_video_b.mp4'\n",
    "# read video\n",
    "input_video_path = os.path.join('../input_videos/', input_video_title)\n",
    "\n",
    "output_video_frames = read_video(input_video_path)\n",
    "\n",
    "# detect ball\n",
    "ball = BallDetector(device, model_last_path, 256)\n",
    "\n",
    "\n",
    "# draw output\n",
    "\n",
    "# for frame in output_video_frames:\n",
    "#     frame = np.array(frame)\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     plt.imshow(frame)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "for frame in output_video_frames:\n",
    "    ball.detect_ball(frame)\n",
    "\n",
    "# print(ball.xy_coordinates)\n",
    "\n",
    "# frame = cv2.cvtColor(output_video_frames[-1], cv2.COLOR_BGR2RGB)\n",
    "# ax = plt.subplot(111)\n",
    "# ax.imshow(frame)\n",
    "\n",
    "    x, y = ball.xy_coordinates[-1]\n",
    "\n",
    "    if x is not None:\n",
    "        cv2.circle(frame, (x, y), 10, (0, 0, 255), -1)\n",
    "\n",
    "## draw frame number on top left corner\n",
    "for i, frame in enumerate(output_video_frames):\n",
    "    cv2.putText(frame, f'Frame: {i}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "output_video_title = input_video_title.replace('input', 'output')\n",
    "\n",
    "save_video(output_video_frames, os.path.join('output/', output_video_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
