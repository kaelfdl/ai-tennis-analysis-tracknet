{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#!wget 'https://drive.usercontent.google.com/download?id=1DQ3ZbvokTsgOq6x-ay6O8U2W4a8e3LFw&export=download&confirm=yes' -O 'dataset/tennis_ball_det_dataset.zip'\n","#!unzip 'dataset/tennis_ball_det_dataset.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:56:53.804050Z","iopub.status.busy":"2024-05-20T09:56:53.803711Z","iopub.status.idle":"2024-05-20T09:57:29.035594Z","shell.execute_reply":"2024-05-20T09:57:29.034733Z","shell.execute_reply.started":"2024-05-20T09:56:53.804021Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import cv2\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","import math\n","from matplotlib.patches import Circle\n","\n","import time\n","\n","import torch.distributed as dist\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","import torch_xla.distributed.parallel_loader as pl\n","import multiprocessing as mp\n","\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","\n","from torch_xla import runtime as xr\n","import torch_xla.distributed.xla_backend # Registers `xla://` init_method\n","import torch_xla.experimental.pjrt_backend # Required for torch.distributed on TPU v2 and v3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.037675Z","iopub.status.busy":"2024-05-20T09:57:29.037310Z","iopub.status.idle":"2024-05-20T09:57:29.045697Z","shell.execute_reply":"2024-05-20T09:57:29.044795Z","shell.execute_reply.started":"2024-05-20T09:57:29.037647Z"},"trusted":true},"outputs":[],"source":["torch.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.046963Z","iopub.status.busy":"2024-05-20T09:57:29.046686Z","iopub.status.idle":"2024-05-20T09:57:29.058050Z","shell.execute_reply":"2024-05-20T09:57:29.057387Z","shell.execute_reply.started":"2024-05-20T09:57:29.046936Z"},"trusted":true},"outputs":[],"source":["torch_xla.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.059963Z","iopub.status.busy":"2024-05-20T09:57:29.059694Z","iopub.status.idle":"2024-05-20T09:57:29.069686Z","shell.execute_reply":"2024-05-20T09:57:29.069013Z","shell.execute_reply.started":"2024-05-20T09:57:29.059936Z"},"trusted":true},"outputs":[],"source":["os.getenv('PJRT_DEVICE')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.072454Z","iopub.status.busy":"2024-05-20T09:57:29.072220Z","iopub.status.idle":"2024-05-20T09:57:29.082610Z","shell.execute_reply":"2024-05-20T09:57:29.081950Z","shell.execute_reply.started":"2024-05-20T09:57:29.072431Z"},"trusted":true},"outputs":[],"source":["print(os.getenv('TPU_PROCESS_ADDRESSES'))\n","print(os.getenv('CLOUD_TPU_TASK_ID'))\n","\n","# Temporary hack: remove some TPU environment variables to support multiprocessing\n","# These will be set later by xmp.spawn.\n","os.environ.pop('TPU_PROCESS_ADDRESSES')\n","os.environ.pop('CLOUD_TPU_TASK_ID')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.083715Z","iopub.status.busy":"2024-05-20T09:57:29.083464Z","iopub.status.idle":"2024-05-20T09:57:29.169555Z","shell.execute_reply":"2024-05-20T09:57:29.167735Z","shell.execute_reply.started":"2024-05-20T09:57:29.083689Z"},"trusted":true},"outputs":[],"source":["lock = mp.Manager().Lock()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:29.172540Z","iopub.status.busy":"2024-05-20T09:57:29.172186Z","iopub.status.idle":"2024-05-20T09:57:34.486617Z","shell.execute_reply":"2024-05-20T09:57:34.485348Z","shell.execute_reply.started":"2024-05-20T09:57:29.172508Z"},"trusted":true},"outputs":[],"source":["def print_device(i, lock):\n","    device = xm.xla_device()\n","    with lock:\n","        print('process', i, device)\n","        \n","xmp.spawn(print_device, args=(lock,), start_method='fork')"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def add_ones(i, lock):\n","    x = torch.ones((3, 3), device=xm.xla_device())\n","    y = x + x\n","    \n","    # Run graph to compute `y` before printing\n","    xm.mark_step()\n","    \n","    with lock:\n","        print(i, y)\n","\n","xmp.spawn(add_ones, args=(lock,), start_method='fork')"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def gather_ids(i, lock):\n","    # Create a tensor on each device with the device ID\n","    t = torch.tensor([i], device=xm.xla_device())\n","    with lock:\n","        print(i, t)\n","    \n","    # Collect and concatenate the IDs\n","    ts = xm.all_gather(t)\n","    xm.mark_step()\n","    with lock:\n","        print(i, ts)\n","\n","xmp.spawn(gather_ids, args=(lock,), start_method='fork')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:34.488498Z","iopub.status.busy":"2024-05-20T09:57:34.488191Z","iopub.status.idle":"2024-05-20T09:57:34.500778Z","shell.execute_reply":"2024-05-20T09:57:34.499934Z","shell.execute_reply.started":"2024-05-20T09:57:34.488467Z"},"trusted":true},"outputs":[],"source":["seed = 24\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device\n","\n","BASE_INPUT_DIR = '/kaggle/input/tennis-ball-tracknet/'"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["path = os.path.join(BASE_INPUT_DIR, 'dataset/tennis_ball/images/game1/Clip1/Label.csv')\n","\n","with open(path, 'r') as f:\n","    df = pd.read_csv(f)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def gaussian_kernel(size, variance):\n","    x, y = np.mgrid[-size:size+1, -size:size+1]\n","    g = np.exp(-(x**2 + y**2)/float(2*variance))\n","    return g\n","\n","variance = 10\n","g = gaussian_kernel(1, variance)\n","print(len(g))\n","plt.imshow(g, cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_gaussian(size, variance):\n","    gaussian_kernel_array = gaussian_kernel(size, variance)\n","    gaussian_kernel_array = gaussian_kernel_array * 255 / gaussian_kernel_array[int(len(gaussian_kernel_array) / 2)][int(len(gaussian_kernel_array) / 2)]\n","    gaussian_kernel_array = gaussian_kernel_array.astype(int)\n","    return gaussian_kernel_array\n","\n","img = create_gaussian(3, 10)\n","print(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_ground_truth_images(path_input, path_output, size, variance, width, height):\n","    gaussian_kernel_array = create_gaussian(size, variance)\n","    for game_id in range(1,11):\n","        game = f'game{game_id}'\n","        clips = os.listdir(os.path.join(path_input, game))\n","        for clip in clips:\n","            print(f'game = {game}, clip = {clip}')\n","\n","            path_out_game = os.path.join(path_output, game)\n","            if not os.path.exists(path_out_game):\n","                os.makedirs(path_out_game)\n","            \n","            path_out_clip = os.path.join(path_out_game, clip)\n","            if not os.path.exists(path_out_clip):\n","                os.makedirs(path_out_clip)\n","\n","            path_labels = os.path.join(os.path.join(path_input, game, clip), 'Label.csv')\n","            labels = pd.read_csv(path_labels)\n","            for idx in range(labels.shape[0]):\n","                file_name, vis, x, y, _ = labels.loc[idx, :]\n","                heatmap = np.zeros((height, width, 3), dtype=np.uint8)\n","                if vis != 0:\n","                    x = int(x)\n","                    y = int(y)\n","                    for i in range(-size, size+1):\n","                        for j in range(-size, size+1):\n","                            if x+i < width and x+i >= 0 and y+j < height and y+j >= 0:\n","                                temp = gaussian_kernel_array[i+size][j+size]\n","                                if temp > 0:\n","                                    heatmap[y+j, x+i] = (temp, temp, temp)\n","                    \n","                cv2.imwrite(os.path.join(path_out_clip, file_name), heatmap)\n","\n","#create_ground_truth_images('dataset/tennis_ball/images', 'dataset/tennis_ball/gts', 20, 10, 1280, 720)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def create_ground_truth_labels(path_input, path_output, train_rate=0.7):\n","    df = pd.DataFrame()\n","    for game_id in range(1, 11):\n","        game = f'game{game_id}'\n","        clips = os.listdir(os.path.join(path_input, game))\n","        for clip in clips:\n","            labels = pd.read_csv(os.path.join(path_input, game, clip, 'Label.csv'))\n","            labels['ground_truth_path'] = 'gts/' + game + '/' + clip + '/' + labels['file name']\n","            labels['path1'] = 'images/' + game + '/' + clip + '/' + labels['file name']\n","            labels_target = labels[2:]\n","            labels_target.loc[:, 'path2'] = list(labels['path1'][1:-1])\n","            labels_target.loc[:, 'path3'] = list(labels['path1'][:-2])\n","            df = pd.concat([df, labels_target])\n","\n","    df = df.reset_index(drop=True)\n","    df = df[['path1', 'path2', 'path3', 'ground_truth_path', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n","    df = df.sample(frac=1)\n","    num_train = int(df.shape[0] * train_rate)\n","    df_train = df[:num_train]\n","    df_val = df[num_train:]\n","    df_train.to_csv(os.path.join(path_output, 'labels_train.csv'), index=False)\n","    df_val.to_csv(os.path.join(path_output, 'labels_val.csv'), index=False)\n","\n","#create_ground_truth_labels('dataset/tennis_ball/images', 'dataset/tennis_ball')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:34.502206Z","iopub.status.busy":"2024-05-20T09:57:34.501936Z","iopub.status.idle":"2024-05-20T09:57:34.512219Z","shell.execute_reply":"2024-05-20T09:57:34.511383Z","shell.execute_reply.started":"2024-05-20T09:57:34.502179Z"},"trusted":true},"outputs":[],"source":["def combine_three_frames(frame1, frame2, frame3, width, height):\n","    # Resize and type converting for each frame\n","    img = cv2.resize(frame1, (width, height))\n","    # Input must be float type\n","    img = img.astype(np.float32)\n","\n","    # Resize\n","    img1 = cv2.resize(frame2, (width, height))\n","    # Input must be float type\n","    img1 = img1.astype(np.float32)\n","\n","    # Resize\n","    img2 = cv2.resize(frame3, (width, height))\n","    # Input must be float type\n","    img2 = img2.astype(np.float32)\n","\n","    # combine three images to (width, height, rgb * 3)\n","    imgs = np.concatenate((img, img1, img2), axis=2)\n","\n","    # since the ordering of TrackNet is channels first, we need to change the axis\n","    imgs = np.rollaxis(imgs, 2, 0)\n","\n","    return np.array(imgs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:34.515426Z","iopub.status.busy":"2024-05-20T09:57:34.515170Z","iopub.status.idle":"2024-05-20T09:57:34.548549Z","shell.execute_reply":"2024-05-20T09:57:34.547786Z","shell.execute_reply.started":"2024-05-20T09:57:34.515401Z"},"trusted":true},"outputs":[],"source":["class BallDataset(Dataset):\n","    def __init__(self, mode, input_height=360, input_width=640):\n","        self.path_dataset = os.path.join(BASE_INPUT_DIR, 'dataset/tennis_ball')\n","        assert mode in ['train', 'val'], 'incorrect mode'\n","        self.data = pd.read_csv(os.path.join(self.path_dataset, f'labels_{mode}.csv'))\n","        xm.master_print(f'mode = {mode}, samples = {self.data.shape[0]}') \n","\n","        self.width = input_width\n","        self.height = input_height\n","\n","\n","    \n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","\n","    def __getitem__(self, idx):\n","        path, path_prev, path_preprev, path_gt, x, y, status, vis = self.data.loc[idx, :]\n","\n","        path = os.path.join(self.path_dataset, path)\n","        path_prev = os.path.join(self.path_dataset, path_prev)\n","        path_preprev = os.path.join(self.path_dataset, path_preprev)\n","        path_gt = os.path.join(self.path_dataset, path_gt)\n","\n","        if math.isnan(x):\n","            x = -1\n","            y = -1\n","        \n","        inputs = self.get_input(path, path_prev, path_preprev)\n","        outputs = self.get_output(path_gt)\n","\n","        return inputs, outputs, x, y, vis\n","\n","    def get_input(self, path, path_prev, path_preprev):\n","        img = cv2.imread(path)\n","        img = cv2.resize(img, (self.width, self.height))\n","\n","        img_prev = cv2.imread(path_prev)\n","        img_prev = cv2.resize(img_prev, (self.width, self.height))\n","\n","        img_preprev = cv2.imread(path_preprev)\n","        img_preprev = cv2.resize(img_preprev, (self.width, self.height))\n","\n","        imgs = np.concatenate((img, img_prev, img_preprev), axis=2)\n","        imgs = imgs.astype(np.float32) / 255.0\n","\n","        imgs = np.rollaxis(imgs, 2, 0)\n","\n","        return imgs\n","\n","    def get_output(self, path_gt):\n","        img = cv2.imread(path_gt)\n","        img = cv2.resize(img, (self.width, self.height))\n","        img = img[:, :, 0]\n","        img = np.reshape(img, (self.width * self.height))\n","        return img\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["train_dataset = BallDataset('train')\n","# train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=2, num_workers=4, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["imgs, gt, x, y, vis = next(iter(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["x = x[0]\n","y = y[0]\n","\n","a = np.array(imgs[0])\n","b = a[:3]\n","c = a[3:6]\n","d = a[6:]\n","# a = np.rollaxis(a, 0, 3)\n","b = np.rollaxis(b, 0, 3)\n","c = np.rollaxis(c, 0, 3)\n","d = np.rollaxis(d, 0, 3)\n","fig, ax = plt.subplots(4, 1, figsize=(20, 20))\n","\n","e = np.array(gt)\n","e = np.reshape(e[0], (360, 640, 1))\n","\n","ax = plt.subplot(411)\n","ax.imshow(e, cmap='gray')\n","print(x/2, y/2)\n","circle = Circle((x/2, y/2), 5)\n","ax.add_patch(circle)\n","ax = plt.subplot(412)\n","ax.imshow(b)\n","ax = plt.subplot(413)\n","ax.imshow(c)\n","ax = plt.subplot(414)\n","ax.imshow(d)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<img src='notebook_images/tracknet_architecture.png' style='width:720px'>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:34.549899Z","iopub.status.busy":"2024-05-20T09:57:34.549595Z","iopub.status.idle":"2024-05-20T09:57:34.598410Z","shell.execute_reply":"2024-05-20T09:57:34.597626Z","shell.execute_reply.started":"2024-05-20T09:57:34.549857Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True, bn=True):\n","        super().__init__()\n","        if bn:\n","            self.block = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias),\n","                nn.ReLU(),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        else:\n","            self.block = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias),\n","                nn.ReLU()\n","            )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","    \n","class BallTrackNet(nn.Module):\n","    def __init__(self, out_channels=256, bn=True):\n","        super().__init__()\n","        self.out_channels = out_channels\n","\n","        # Encoder layers\n","        layer_1 = ConvBlock(in_channels=9, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_2 = ConvBlock(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        layer_4 = ConvBlock(in_channels=64, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_5 = ConvBlock(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_6 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        layer_7 = ConvBlock(in_channels=128, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_8 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_9 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_10 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        layer_11 = ConvBlock(in_channels=256, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_12 = ConvBlock(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_13 = ConvBlock(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=True, bn=bn)\n","\n","        self.encoder = nn.Sequential(layer_1, layer_2, layer_3, layer_4, layer_5, layer_6, layer_7, layer_8, layer_9, layer_10, layer_11, layer_12, layer_13)\n","        \n","        # Decoder layers\n","        layer_14 = nn.Upsample(scale_factor=2)\n","        layer_15 = ConvBlock(in_channels=512, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_16 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_17 = ConvBlock(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_18 = nn.Upsample(scale_factor=2)\n","        layer_19 = ConvBlock(in_channels=256, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_20 = ConvBlock(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_21 = nn.Upsample(scale_factor=2)\n","        layer_22 = ConvBlock(in_channels=128, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_23 = ConvBlock(in_channels=64, out_channels=64, kernel_size=3, padding=1, bias=True, bn=bn)\n","        layer_24 = ConvBlock(in_channels=64, out_channels=self.out_channels, kernel_size=3, padding=1, bias=True, bn=bn)\n","\n","        self.decoder = nn.Sequential(layer_14, layer_15, layer_16, layer_17, layer_18, layer_19, layer_20, layer_21, layer_22, layer_23, layer_24)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","        self._init_weights()\n","    \n","\n","    def forward(self, x, testing=False):\n","        batch_size = x.size(0)\n","        features = self.encoder(x)\n","        scores_map = self.decoder(features)\n","        output = scores_map.reshape(batch_size, self.out_channels, -1)\n","\n","        if testing:\n","            output = self.softmax(output)\n","\n","        return output\n","    \n","    def _init_weights(self):\n","        for module in self.modules():\n","            if isinstance(module, nn.Conv2d):\n","                nn.init.uniform_(module.weight, -0.05, 0.05)\n","                if module.bias is not None:\n","                    nn.init.constant_(module.bias, 0)\n","            elif isinstance(module, nn.BatchNorm2d):\n","                nn.init.constant_(module.weight, 1)\n","                nn.init.constant_(module.bias, 0)\n","    \n","    def inference(self, frames: torch.Tensor):\n","        self.eval()\n","        with torch.no_grad():\n","            if len(frames.shape) == 3:\n","                frames = frames.unsqueeze(0)\n","            if next(self.parameters()).is_cuda:\n","                frames.cuda()\n","\n","            # Forward pass\n","            output = self(frames, True)\n","            output = output.argmax(dim=1).detach().cpu().numpy()\n","            if self.out_channels == 2:\n","                output *= 255\n","            x, y = self.get_center_ball(output)\n","\n","        return x, y\n","\n","    \n","    def get_center_ball(self, output):\n","    \n","        output = output.reshape((360, 640))\n","\n","        # cv2 image must be np.uint8\n","        output = output.astype(np.uint8)\n","\n","        # reshape image size\n","        heatmap = cv2.resize(output, (640, 360))\n","\n","        # heatmap is converted into a binary image by threshold method\n","        ret, heatmap = cv2.threshold(heatmap, 127, 255, cv2.THRESH_BINARY)\n","\n","        # find the circle in image with 2 <= radius <=7\n","        circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=8, minRadius=0, maxRadius=0)\n","        \n","        \n","\n","        # check if there is any tennis ball detected\n","        if circles is not None:\n","            if len(circles) == 1:\n","                x = int(circles[0][0][0])\n","                y = int(circles[0][0][1])\n","            \n","            return x, y\n","        return None, None\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:34.599661Z","iopub.status.busy":"2024-05-20T09:57:34.599398Z","iopub.status.idle":"2024-05-20T09:57:35.447071Z","shell.execute_reply":"2024-05-20T09:57:35.446090Z","shell.execute_reply.started":"2024-05-20T09:57:34.599604Z"},"trusted":true},"outputs":[],"source":["from scipy.spatial import distance\n","\n","def train(model, train_loader, loss_fn, optimizer, device, epoch, max_iters=200):\n","    model.train()\n","\n","    \n","    losses = []\n","    \n","    for iter_id, batch in enumerate(train_loader):\n","#         X, y = torch.randn((128, 128), device=device), torch.randn((128, 10), device=device)\n","        X, y = batch[0].to(device), torch.tensor(batch[1]).to(device)\n","        \n","        optimizer.zero_grad()\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","#         xm.optimizer_step(optimizer)\n","    \n","        # Run the pending graph\n","        xm.mark_step()\n","\n","#         with lock:\n","#             print(f'epoch: {epoch}, loss: {loss:>7f}, iter: [{iter_id}/{max_iters}]')\n","\n","        losses.append(loss.item())\n","        \n","        \n","        # early stop\n","        if iter_id > max_iters - 1:\n","            break\n","            \n","    \n","    return np.mean(losses)\n","\n","\n","def validate(model, val_loader, loss_fn, device, epoch, min_dist=5):\n","    losses = []\n","    tp = [0, 0, 0, 0]\n","    fp = [0, 0, 0, 0]\n","    tn = [0, 0, 0, 0]\n","    fn = [0, 0, 0, 0]\n","    \n","    model.eval()\n","\n","    for iter_id, batch in enumerate(val_loader):\n","        with torch.no_grad():\n","            X, y = batch[0].to(device), torch.tensor(batch[1]).to(device)\n","#             X, y = torch.randn((128, 128), device=device), torch.randn((128, 10), device=device)\n","\n","            \n","            out = model(X)\n","            loss = loss_fn(out, y)\n","            losses.append(loss.item())\n","\n","            # metrics\n","            output = out.argmax(dim=1).detach().cpu().numpy()\n","            for i in range(len(output)):\n","                x_pred, y_pred = postprocess(output[i])\n","                x_gt = batch[2][i].cpu().numpy()\n","                y_gt = batch[3][i].cpu().numpy()\n","                vis = batch[4][i]\n","                \n","                \n","                if x_pred:\n","                    if vis != 0:\n","                        dst = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n","\n","                        if dst < min_dist:\n","                            tp[vis] += 1\n","                        else:\n","                            fp[vis] +=1\n","                    else:\n","                        fp[vis] += 1\n","\n","                if not x_pred:\n","                    if vis != 0:\n","                        fn[vis] += 1\n","                    else:\n","                        tn[vis] += 1\n","            \n","            #print(f'val | epoch = {epoch}, iter = [{iter_id}/{len(val_loader)}, loss = {np.mean(losses):7f}, tp = {sum(tp)}, tn = {sum(tn)}, fp = {sum(fp)}, fn = {sum(fn)}')\n","            \n","    eps = 1e-15\n","    precision = sum(tp) / (sum(tp) + sum(fp) + eps)\n","    vc1 = tp[1] + fp[1] + tn[1] + fn[1]\n","    vc2 = tp[2] + fp[2] + tn[2] + fn[2]\n","    vc3 = tp[3] + fp[3] + tn[3] + fn[3]\n","    recall = sum(tp) / (vc1 + vc2 + vc3 + eps)\n","    f1 = 2* precision * recall / (precision + recall + eps)\n","\n","    print(f'precision = {precision}')\n","    print(f'recall = {recall}')\n","    print(f'f1 = {f1}')\n","    \n","    return np.mean(losses), precision, recall, f1\n","    \n","\n","def postprocess(feature_map, scale=2):\n","    feature_map *= 255\n","    feature_map = feature_map.reshape((360, 640))\n","    feature_map = feature_map.astype(np.uint8)\n","    ret, heatmap = cv2.threshold(feature_map, 127, 255, cv2.THRESH_BINARY)\n","    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=2, maxRadius=7)\n","    x, y = None, None\n","\n","    if circles is not None:\n","        if len(circles) == 1:\n","            x = circles[0][0][0]*scale\n","            y = circles[0][0][1]*scale\n","    \n","    return x, y\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T22:26:21.655967Z","iopub.status.busy":"2024-05-19T22:26:21.655685Z","iopub.status.idle":"2024-05-19T22:26:21.665155Z","shell.execute_reply":"2024-05-19T22:26:21.664361Z","shell.execute_reply.started":"2024-05-19T22:26:21.655942Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class BallDetector:\n","    def __init__(self, device, save_state=None, out_channels=2):\n","        self.device = device\n","\n","        # Load TrackNet model weights\n","        self.detector = BallTrackNet(out_channels=out_channels)\n","        saved_state_dict = torch.load(save_state, map_location=torch.device('cpu'))\n","        self.detector.load_state_dict(saved_state_dict['state_dict'])\n","        self.detector.eval().to(self.device)\n","\n","        self.current_frame = None\n","        self.last_frame = None\n","        self.before_last_frame = None\n","\n","        self.video_width = None\n","        self.video_height = None\n","        self.model_input_width = 640\n","        self.model_input_height = 360\n","\n","        self.threshold_dist = 100\n","        self.xy_coordinates = np.array([[None, None], [None, None]])\n","\n","        self.bounces_indices = []\n","\n","    def detect_ball(self, frame):\n","        # save frame dimensions\n","        if self.video_width is None:\n","            self.video_width = frame.shape[1]\n","            self.video_height = frame.shape[0]\n","        \n","        self.last_frame = self.before_last_frame\n","        self.before_last_frame = self.current_frame\n","        self.current_frame = frame.copy()\n","\n","        # detect only if 3 frames were given\n","        if self.last_frame is not None:\n","            # combine the frames into 1 input tensor\n","            frames = combine_three_frames(self.current_frame, self.before_last_frame, self.last_frame, self.model_input_width, self.model_input_height)\n","\n","            frames = (torch.from_numpy(frames) / 255).to(self.device)\n","\n","            x, y = self.detector.inference(frames)\n","            if x is not None:\n","                # rescale the indices to fit dimensions\n","                x = int(x * (self.video_width / self.model_input_width))\n","                y = int(y * (self.video_height / self.model_input_height))\n","\n","                # check the distance from previous location and remove outliers\n","                if self.xy_coordinates[-1][0] is not None:\n","                    if np.linalg.norm(np.array([x, y]) - self.xy_coordinates[-1]) > self.threshold_dist:\n","                        x, y = None, None\n","        \n","            self.xy_coordinates = np.append(self.xy_coordinates, np.array([[x, y]]), axis=0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:35.448607Z","iopub.status.busy":"2024-05-20T09:57:35.448123Z","iopub.status.idle":"2024-05-20T09:57:35.453756Z","shell.execute_reply":"2024-05-20T09:57:35.453000Z","shell.execute_reply.started":"2024-05-20T09:57:35.448579Z"},"trusted":true},"outputs":[],"source":["import shutil\n","def save_ckp(state, is_best, checkpoint_dir, best_model_dir):\n","    xm.save(state, checkpoint_dir)\n","    if is_best:\n","        shutil.copyfile(checkpoint_dir, best_model_dir)\n","\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","    checkpoint = torch.load(checkpoint_fpath)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer, checkpoint['epoch']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T09:57:35.455488Z","iopub.status.busy":"2024-05-20T09:57:35.455039Z","iopub.status.idle":"2024-05-20T09:57:40.332639Z","shell.execute_reply":"2024-05-20T09:57:40.331450Z","shell.execute_reply.started":"2024-05-20T09:57:35.455436Z"},"trusted":true},"outputs":[],"source":["!pip install tensorboardX torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T10:00:45.391168Z","iopub.status.busy":"2024-05-20T10:00:45.389715Z","iopub.status.idle":"2024-05-20T10:00:45.409055Z","shell.execute_reply":"2024-05-20T10:00:45.408144Z","shell.execute_reply.started":"2024-05-20T10:00:45.391125Z"},"trusted":true},"outputs":[],"source":["from tensorboardX import SummaryWriter\n","from torchinfo import summary\n","\n","exp_id = 4\n","exps_path = f'exps/{exp_id}'\n","\n","tb_path = os.path.join(exps_path, 'plots')\n","if not os.path.exists(tb_path):\n","    os.makedirs(tb_path)\n","log_writer = SummaryWriter(tb_path)\n","model_last_path = os.path.join(exps_path, 'model_last.pt')\n","model_best_path = os.path.join(exps_path, 'model_best.pt')\n","\n","\n","\n","\n","def train_tracknet(index):\n","    device = xm.xla_device()\n","#     model = nn.Linear(128, 10) \n","\n","    model = BallTrackNet()\n","    mx = xmp.MpModelWrapper(model)\n","\n","#     xm.master_print(summary(model, input_size=(2, 9, 360, 640)))\n","\n","    \n","    train_dataset = BallDataset('train')\n","    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=True)\n","    train_loader = DataLoader(train_dataset, batch_size=2, num_workers=0, pin_memory  = True, shuffle=True)\n","#     train_loader = DataLoader(train_dataset, batch_size=2, num_workers=1, sampler=train_sampler, pin_memory  = True)\n","\n","\n","    val_dataset = BallDataset('val')\n","#     val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n","    val_loader = DataLoader(val_dataset, batch_size=2, num_workers=0, pin_memory  = True, shuffle=False)\n","#     val_loader = DataLoader(val_dataset, batch_size=2, num_workers=0, sampler=val_sampler, pin_memory  = True)\n","\n","    dist.init_process_group('xla', init_method='xla://')\n","\n","#     model.to(device)\n","    model = mx.to(device)\n","\n","    if xr.using_pjrt():\n","        xm.broadcast_master_param(model)\n","        \n","    model = DDP(model, gradient_as_bucket_view=True)\n","\n","    \n","#     xla_train_loader = pl.MpDeviceLoader(train_loader, device)\n","#     xla_val_loader = pl.MpDeviceLoader(val_loader, device)\n","    \n","\n","    epochs = 2\n","    steps_per_epoch = 1\n","    lr = 1.0 * xm.xrt_world_size()\n","    \n","    optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","    \n","#     loss_fn = nn.MSELoss()\n","#     optimizer = torch.optim.SGD(model.parameters(), lr=.001)\n","    \n","    val_interval = 1\n","\n","    val_best_metric = 0\n","\n","\n","    start_time = time.time()\n","\n","    start_epoch = 1\n","#     model, optimizer, start_epoch = load_ckp(model_last_path, model, optimizer)\n","    \n","    train_losses = []\n","    val_losses = []\n","    \n","    \n","    for epoch in range(start_epoch, epochs + 1):\n","        train_start_time = time.time()\n","        para_loader = pl.ParallelLoader(train_loader, [device])\n","        train_loss = train(model, para_loader.per_device_loader(device), loss_fn, optimizer, device, epoch, max_iters=steps_per_epoch)\n","#         train_loss = train(model, xla_train_loader, loss_fn, optimizer, device, epoch, max_iters=steps_per_epoch)\n","#         train_loss = train(model, train_loader, loss_fn, optimizer, device, epoch, max_iters=steps_per_epoch)\n","\n","\n","        train_end_time = time.time()\n","        train_duration = time.strftime('%H:%M:%S', time.gmtime(train_end_time - train_start_time))\n","        \n","#         with lock:\n","#             print(f'Train | Epoch: {epoch} / {epochs} | Loss: {train_loss}')\n","\n","        log_writer.add_scalar('Train/training_loss', train_loss, epoch)\n","        log_writer.add_scalar('Train/lr', optimizer.param_groups[0]['lr'], epoch)\n","\n","        checkpoint = {\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","        }\n","        save_ckp(checkpoint, False, model_last_path, model_best_path)\n","        \n","        train_losses.append(train_loss)\n","\n","        xm.master_print(f'Train | Epoch: {epoch} / {epochs} | Loss: {np.mean(train_loss)} | Time: {train_duration}')\n","        \n","        if (epoch > 0) & (epoch % val_interval == 0):\n","            val_start_time = time.time()\n","            para_loader = pl.ParallelLoader(val_loader, [device])\n","            val_loss, precision, recall, f1 = validate(model, para_loader.per_device_loader(device), loss_fn, device, epoch)\n","#             val_loss, precision, recall, f1 = validate(model, xla_val_loader, loss_fn, device, epoch)\n","#             val_loss, precision, recall, f1 = validate(model, val_loader, loss_fn, device, epoch)\n","\n","            \n","            val_end_time = time.time()\n","            val_duration = time.strftime('%H:%M:%S', time.gmtime(val_end_time - val_start_time))\n","            \n","            \n","            log_writer.add_scalar('Val/loss', val_loss, epoch)\n","            log_writer.add_scalar('Val/precision', precision, epoch)\n","            log_writer.add_scalar('Val/recall', recall, epoch)\n","            log_writer.add_scalar('Val/f1', f1, epoch)\n","            \n","            if f1 > val_best_metric:\n","                checkpoint = {\n","                    'epoch': epoch + 1,\n","                    'state_dict': model.state_dict(),\n","                    'optimizer': optimizer.state_dict()\n","                }\n","                val_best_metric = f1\n","                save_ckp(checkpoint, True, model_last_path, model_best_path)\n","                \n","            val_losses.append(val_loss)\n","            xm.master_print(f'Val | Epoch: {epoch} / {epochs} | Loss: {np.mean(val_losses)} | Time: {val_duration}')\n","        \n","\n","        \n","    end_time = time.time()\n","    duration = time.strftime('%H:%M:%S', time.gmtime(end_time - start_time))\n","\n","#     with lock:\n","        # Print mean parameters so we can confirm they're the same across replicas\n","#         print(index, [p.mean() for p in model.parameters()])\n","    xm.master_print(f'Summary | Epochs: {epochs} | Train Loss: {np.mean(train_losses)} | Val Loss: {np.mean(val_losses)} | Time: {duration}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T10:00:48.457202Z","iopub.status.busy":"2024-05-20T10:00:48.456813Z","iopub.status.idle":"2024-05-20T10:42:17.959899Z","shell.execute_reply":"2024-05-20T10:42:17.958630Z","shell.execute_reply.started":"2024-05-20T10:00:48.457168Z"},"trusted":true},"outputs":[],"source":["def _mp_fn(index, lock):\n","    torch.set_default_dtype(torch.float)\n","    train_tracknet(index)\n","\n","FLAGS = {}\n","\n","xmp.spawn(_mp_fn, args=(lock,), start_method='fork')"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","from utils.video_utils import read_video, save_video\n","\n","input_video_title = 'input_video_b.mp4'\n","# read video\n","input_video_path = os.path.join('../input_videos/', input_video_title)\n","\n","output_video_frames = read_video(input_video_path)\n","\n","# detect ball\n","ball = BallDetector(device, model_last_path, 256)\n","\n","\n","# draw output\n","\n","# for frame in output_video_frames:\n","#     frame = np.array(frame)\n","#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","#     plt.imshow(frame)\n","#     plt.show()\n","\n","\n","for frame in output_video_frames:\n","    ball.detect_ball(frame)\n","\n","# print(ball.xy_coordinates)\n","\n","# frame = cv2.cvtColor(output_video_frames[-1], cv2.COLOR_BGR2RGB)\n","# ax = plt.subplot(111)\n","# ax.imshow(frame)\n","\n","    x, y = ball.xy_coordinates[-1]\n","\n","    if x is not None:\n","        cv2.circle(frame, (x, y), 10, (0, 0, 255), -1)\n","\n","## draw frame number on top left corner\n","for i, frame in enumerate(output_video_frames):\n","    cv2.putText(frame, f'Frame: {i}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","\n","output_video_title = input_video_title.replace('input', 'output')\n","\n","save_video(output_video_frames, os.path.join('output/', output_video_title))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def toy_model(index, lock):\n","    device = xm.xla_device()\n","    dist.init_process_group('xla', init_method='xla://')\n","\n","    # Initialize a basic toy model\n","    torch.manual_seed(42)\n","    model = nn.Linear(128, 10).to(device)\n","\n","    # Optional for TPU v4 and GPU\n","    xm.broadcast_master_param(model)\n","    \n","    # `gradient_as_bucket_view=True` required for XLA\n","    model = DDP(model, gradient_as_bucket_view=True)\n","\n","    \n","\n","    loss_fn = nn.MSELoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=.001)\n","\n","    for i in range(10):\n","        # Generate random inputs and outputs on the XLA device\n","        data, target = torch.randn((128, 128), device=device), torch.randn((128, 10), device=device)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","\n","        optimizer.step()\n","        \n","        # Run the pending graph\n","        xm.mark_step()\n","\n","    with lock:\n","        # Print mean parameters so we can confirm they're the same across replicas\n","        print(index, [p.mean() for p in model.parameters()])\n","\n","xmp.spawn(toy_model, args=(lock,), start_method='fork')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4950725,"sourceId":8336032,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
